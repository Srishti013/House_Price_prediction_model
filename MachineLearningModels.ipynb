{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Models \n",
    "Let's apply machine learning techniques to our transformed data.\n",
    "\n",
    "### Select and Train Models \n",
    "We'll split the transformed data set into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test formate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_X_prepared, housing_y_prepared, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Linear Regression** Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "\n",
    "# Invert the log-transformed value\n",
    "def inv_y(transformed_y):\n",
    "    return np.exp(transformed_y)\n",
    "\n",
    "# Series to collect RMSE for the different algorithms: \"algorithm name + rmse\"\n",
    "rmse_compare = pd.Series()\n",
    "rmse_compare.index.name = 'Model'\n",
    "\n",
    "# Series to collect accuracy scores for the different algorithms: \"algorithm name + score\"\n",
    "scores_compare = pd.Series()\n",
    "scores_compare.index.name = 'Model'\n",
    "\n",
    "# Model 1: Linear Regression =================================================\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "linear_val_predictions = linear_model.predict(X_test)\n",
    "linear_val_rmse = mean_squared_error(inv_y(linear_val_predictions), inv_y(y_test))\n",
    "linear_val_rmse = np.sqrt(linear_val_rmse)\n",
    "rmse_compare['LinearRegression'] = linear_val_rmse\n",
    "\n",
    "lr_score = linear_model.score(X_test, y_test)*100\n",
    "scores_compare['LinearRegression'] = lr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Decision Trees** Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Trees. Define the model. =============================\n",
    "dtree_model = DecisionTreeRegressor(random_state=5)\n",
    "dtree_model.fit(X_train, y_train)\n",
    "\n",
    "dtree_val_predictions = dtree_model.predict(X_test)\n",
    "dtree_val_rmse = mean_squared_error(inv_y(dtree_val_predictions), inv_y(y_test))\n",
    "dtree_val_rmse = np.sqrt(dtree_val_rmse)\n",
    "rmse_compare['DecisionTree'] = dtree_val_rmse\n",
    "\n",
    "dtree_score = dtree_model.score(X_test, y_test)*100\n",
    "scores_compare['DecisionTree'] = dtree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Random Forest** ALgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest. Define the model. =============================\n",
    "rf_model = RandomForestRegressor(random_state=5)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_val_predictions = rf_model.predict(X_test)\n",
    "rf_val_rmse = mean_squared_error(inv_y(rf_val_predictions), inv_y(y_test))\n",
    "rf_val_rmse = np.sqrt(rf_val_rmse)\n",
    "rmse_compare['RandomForest'] = rf_val_rmse\n",
    "\n",
    "rf_score = rf_model.score(X_test, y_test)*100\n",
    "scores_compare['RandomForest'] = rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Gradiest Boosting** Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Gradient Boosting Regression ==========================================\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, \n",
    "                                      max_depth=4, random_state=5)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "gbr_val_predictions = gbr_model.predict(X_test)\n",
    "gbr_val_rmse = mean_squared_error(inv_y(gbr_val_predictions), inv_y(y_test))\n",
    "gbr_val_rmse = np.sqrt(gbr_val_rmse)\n",
    "rmse_compare['GradientBoosting'] = gbr_val_rmse\n",
    "\n",
    "gbr_score = gbr_model.score(X_test, y_test)*100\n",
    "scores_compare['GradientBoosting'] = gbr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating **Root Mean Square Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE values for different algorithms:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model\n",
       "LinearRegression    24663.0\n",
       "GradientBoosting    27212.0\n",
       "RandomForest        31491.0\n",
       "DecisionTree        37872.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('RMSE values for different algorithms:')\n",
    "rmse_compare.sort_values(ascending=True).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating **Accuracy** by applying different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for different algorithms:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model\n",
       "GradientBoosting    89.567\n",
       "LinearRegression    89.546\n",
       "RandomForest        84.796\n",
       "DecisionTree        72.805\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy scores for different algorithms:')\n",
    "scores_compare.sort_values(ascending = False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest model, Linear Regression, seems to be performing the best, with predicted prices that are off by about 24K. This might or might not be an acceptable amount of deviation – depends on the desired level of accuracy or the metric we are trying to optimize based on our business objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "\n",
    "Let’s perform a K-fold cross-validation on our best model: the cross-validation function randomly splits the training set into K distinct subsets (folds), then it trains and evaluates the model K times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the K evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.11258486 0.1387038  0.10560685 0.12879515 0.10938266 0.11523122\n",
      " 0.10957026 0.11720692 0.13331768 0.11522458]\n",
      "Mean: 0.11856239964913914\n",
      "Standard deviation: 0.010587173458107472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(linear_model, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "linear_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "display_scores(linear_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.13156435 0.17088973 0.12085582 0.16462507 0.13179427 0.14031469\n",
      " 0.14391635 0.11671486 0.15015448 0.14648264]\n",
      "Mean: 0.14173122731360774\n",
      "Standard deviation: 0.016548003161403323\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf_model, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can notice that cross-validation gives us the mean and standard deviation for the scores as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
